# AWS
awsAccessKeyId=XXXXXXXXXXXXXXXX
awsSecretAccessKey=XXXXXXXXXXXXXXXXXXXXXXXXXX

collection=collection1
baseDir=/data/collections/${collection}

# Ingest
doIngest=true
mapperClass=com.lucid.sda.hadoop.ingest.DirectoryIngestMapper
inputDir=
inputType=application/pdf
workingDir=${baseDir}/tmp/
overwrite=true

# Extraction
doExtract=true
tikaProcessorClass=com.digitalpebble.behemoth.tika.TikaProcessor

# Vectorization
vec_nGrams=1
vec_analyzer=com.lucid.sda.hadoop.analysis.StandardStopwordAnalyzer
#vec_analyzer=org.apache.mahout.vectorizer.DefaultAnalyzer

# Sub-workflows
doKMeans=false
doSIPs=false
doSimdoc=false
#Named Entity Recognition
doAnnotations=false

# KMeans
kmeans_numClusters=20
kmeans_maxIter=10
kmeans_distanceMeasure=org.apache.mahout.common.distance.CosineDistanceMeasure
kmeans_convergenceDelta=0.5

solr_zkHost=

#Sips
sips_maxNGramSize=2
sips_minLLR=1

#Simdoc
simdoc_threshold=0
zkhost=

#Percent of docs if failed will cause wf to fail
solrFailedThresholdPercent=25

#App Share Lib
oozie.libpath=${nameNode}/user/hadoop/share/lib

numberOfRegions=50

idField=id
#CSV
csvFieldMapping=0\=id
# May be: default, excel, tdf or a fully qualified class name
csvStrategy=default
